# These values are used more than once, so we'll set them here with appropriate defaults
env:
  wds:
    db:
      host: ${WDS_DB_HOST:localhost}
      port: ${WDS_DB_PORT:5432}
      name: ${WDS_DB_NAME:wds}
      password: ${WDS_DB_PASSWORD:wds}
      user: ${WDS_DB_USER:wds}
      # When running on Azure in k8s with workload identity set ADDITIONAL_JDBC_URL_PARAMS to
      # sslmode=require&authenticationPluginClassName=com.azure.identity.extensions.jdbc.postgresql.AzurePostgresqlAuthenticationPlugin
      additionalUrlParams: ${ADDITIONAL_JDBC_URL_PARAMS:prepareThreshold=0}

management:
  endpoint:
    info:
      access: read_only
    health:
      access: read_only
      show-details: ALWAYS
      probes:
        enabled: true
      group:
        liveness:
          include: livenessState,db
    prometheus:
      access: read_only
  endpoints:
    access:
      default: none
      max-permitted: read_only
    web:
      exposure:
        include: "info,health,prometheus"
      base-path: /
      path-mapping:
        info: version
        health: status
        prometheus: prometheus
  health:
    defaults:
      enabled: false
    db:
      enabled: true
    ping:
      enabled: true
    pubsub:
      enabled: true

  # additional keys to expose in the actuator info endpoint:
  info:
    env:
      enabled: true
  prometheus:
    metrics:
      export:
        enabled: true

info:
  app:
    chart-version: ${HELM_CHART:unknown}
    image: ${WDS_IMAGE:unknown}

spring:
  cache:
    jcache:
      config: classpath:ehcache.xml

  cloud:
    gcp:
      core:
        enabled: false
      storage:
        enabled: false
      secretmanager:
        # WDS does not use secret manager, but GCP starter libraries attempt to autoconfigure it.
        # Explicitly disable it here to avoid problems with autoconfig.
        enabled: false

  datasource:
    hikari:
      jdbc-url: jdbc:postgresql://${env.wds.db.host}:${env.wds.db.port}/${env.wds.db.name}?reWriteBatchedInserts=true&${env.wds.db.additionalUrlParams}
      username: ${env.wds.db.user}
      password: ${env.wds.db.password}
      maximum-pool-size: 7
      minimum-idle: 7
  mvc:
    problemdetails:
      # TODO AJ-1157: can we turn this back on?
      enabled: false
  servlet:
    multipart.max-request-size: 5GB
    multipart.max-file-size: 5GB
  sql:
    init:
      # Disable having spring-boot from automatically creating the schema for the embedded datasource
      mode: never
  # ... and run Liquibase instead
  liquibase:
    change-log: classpath:liquibase/changelog.yaml
  quartz:
    # Quartz will persist all its information in memory. This is simple and performant and
    # allows Quartz to use sensitive data such as auth tokens as input to jobs. However,
    # it is not restart-safe; if WDS restarts or dies before a Quartz job completes, that
    # job will be lost and appear to the end user as if it hung.
    # It is also not cluster-aware; when WDS runs as a multi-replica cluster, Quartz jobs will
    # always run on the replica where they were created.
    job-store-type: memory
    wait-for-jobs-to-complete-on-shutdown: true

#   # activate the "local" profile to turn on CORS response headers,
#   # which may be necessary for local development.
#   profiles:
#     active: local

# set hikari logging to DEBUG or even TRACE to troubleshoot connection pool issues
logging:
  level:
    com.zaxxer.hikari.HikariConfig: INFO
    com.zaxxer.hikari: INFO
server:
  error:
    include-stacktrace: never
    include-message: always
  tomcat:
    # relative redirects fix issues redirecting to swagger-ui in BEEs
    use-relative-redirects: true

twds:
  write.batch.size: 5000
  streaming.fetch.size: 5000
  instance:
    # Workspace Id for launching instance
    workspace-id: ${WORKSPACE_ID:}
    source-workspace-id: ${SOURCE_WORKSPACE_ID:}
  # short-lived credentials to use during cloning
  startup-token: ${STARTUP_TOKEN:}
  # tenancy & data-import defaults match data-plane, but the source of truth for these configs
  # should be application-data-plane.yml or application-control-plane.yml; they are provided here
  # to allow Spring to boot without crashing and allow StartupConfig to run and check preconditions
  tenancy:
    allow-virtual-collections: false
    require-env-workspace: true
    enforce-collections-match-workspace-id: true
  data-import:
    connectivity-check-enabled: false
    allowed-hosts:
      - anvil\.gi\.ucsc\.edu
      - .*\.singlecell\.gi\.ucsc\.edu,
      - .*gen3\.biodatacatalyst\.nhlbi\.nih\.gov
      - .*service\.azul\.data\.humancellatlas\.org
    sources:
      - urls:
          - ^https:\/\/.*gen3\.biodatacatalyst\.nhlbi\.nih\.gov\/
          - ^https:\/\/gen3-biodatacatalyst-nhlbi-nih-gov-pfb-export\.s3\.amazonaws\.com\/
          - ^https:\/\/s3\.amazonaws.com\/gen3-biodatacatalyst-nhlbi-nih-gov-pfb-export\/
          - ^https:\/\/pic-sure-auth-prod-data-export\.s3\.amazonaws\.com\/
          - ^https:\/\/s3\.amazonaws\.com\/pic-sure-auth-prod-data-export\/
          - ^https:\/\/s3\.amazonaws\.com\/edu-ucsc-gi-platform-anvil-prod-storage-anvilprod\.us-east-1\/
          - ^https:\/\/nih-nhlbi-.*\.amazonaws\.com\/
          # anvil data is in TDR now, these are the old URLs
          - ^https:\/\/gen3-theanvil-io-pfb-export\.s3\.amazonaws\.com\/
          - ^https:\/\/s3\.amazonaws\.com\/gen3-theanvil-io-pfb-export\/
        requirePrivateWorkspace: true
        requireProtectedDataPolicy: true
        requiredAuthDomainGroups:
          - "federal_data_lockdown"

  pg_dump:
    path: ${PGDUMP_PATH:/usr/bin/pg_dump}
    psqlPath: ${PSQL_PATH:/usr/bin/psql}
    port: ${env.wds.db.port}
    user: ${env.wds.db.user}
    dbName: ${env.wds.db.name}
    password: ${env.wds.db.password}
    host: ${env.wds.db.host}
    # When running on Azure in k8s with workload identity set PGDUMP_USE_AZURE_IDENTITY to true
    useAzureIdentity: ${PGDUMP_USE_AZURE_IDENTITY:true}

# retry configuration for REST clients (Sam, TDR, etc)
rest:
  retry:
    maxAttempts: 5
    backoff:
      delay: 500
      multiplier: 1.5

# retry configuration for WDS APIs
api:
  retry:
    maxAttempts: 10
    backoff:
      delay: 150
      multiplier: 1.5

# configuration for the Rawls REST client
rawls:
  connectTimeout: 10
  readTimeout: 45
